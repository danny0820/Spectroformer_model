# æ¸¬è©¦æ¨¡å‹è…³æœ¬
import argparse
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
from final_model_AGSSF1 import mymodel

# è§£æå‘½ä»¤åˆ—åƒæ•¸
parser = argparse.ArgumentParser(description='Spectroformer æ¸¬è©¦è…³æœ¬')
parser.add_argument('--dataset_path', default='/danny/Spectroformer_model/LSUI', help='LSUI è³‡æ–™é›†çš„è·¯å¾‘')
parser.add_argument('--model_path', required=True, help='æ¨¡å‹æª¢æŸ¥é»æª”æ¡ˆè·¯å¾‘')
parser.add_argument('--batch_size', type=int, default=1, help='æ¸¬è©¦æ‰¹æ¬¡å¤§å°')
parser.add_argument('--output_dir', type=str, default='./test_results', help='å„²å­˜æ¸¬è©¦çµæœçš„è³‡æ–™å¤¾')
parser.add_argument('--save_images', action='store_true', default=False, help='æ˜¯å¦å„²å­˜æ¸¬è©¦çµæœåœ–ç‰‡')
opt = parser.parse_args()

# è¨­å®šè£ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è£ç½®: {device}")

class LSUITestDataset(Dataset):
    """LSUI æ¸¬è©¦è³‡æ–™é›†"""
    def __init__(self, data_path, transform=None):
        self.data_path = os.path.join(data_path, 'test')
        self.degraded_path = os.path.join(self.data_path, 'input')
        self.gt_path = os.path.join(self.data_path, 'gt')
        self.image_files = sorted(os.listdir(self.degraded_path))
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        degraded_img = Image.open(os.path.join(self.degraded_path, img_name)).convert('RGB')
        gt_img = Image.open(os.path.join(self.gt_path, img_name)).convert('RGB')

        if self.transform:
            degraded_img = self.transform(degraded_img)
            gt_img = self.transform(gt_img)
            
        return degraded_img, gt_img, img_name

def save_img(img_tensor, filename):
    """å°‡å¼µé‡ä¿å­˜ç‚ºåœ–ç‰‡"""
    if len(img_tensor.shape) == 3:
        img = transforms.ToPILImage()(img_tensor.clamp(0, 1))
        img.save(filename)

def load_model(model_path, device):
    """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
    print(f"è¼‰å…¥æ¨¡å‹: {model_path}")
    
    # åˆå§‹åŒ–æ¨¡å‹ - ä½¿ç”¨ final_model_AGSSF1.py ä¸­çš„ mymodel
    net_g = mymodel(
        num_blocks=[2, 3, 3, 4], 
        num_heads=[1, 2, 4, 8], 
        channels=[16, 32, 64, 128], 
        num_refinement=4,
        expansion_factor=2.66, 
        ch=[64, 32, 16, 64]
    )
    
    # è¼‰å…¥æª¢æŸ¥é»
    if os.path.isfile(model_path):
        checkpoint = torch.load(model_path, map_location=device)
        
        # è™•ç†ä¸åŒæ ¼å¼çš„æª¢æŸ¥é»
        if isinstance(checkpoint, dict):
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            elif 'model' in checkpoint:
                state_dict = checkpoint['model']
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint
            
        # å¦‚æœæ˜¯DataParallelæ¨¡å‹ï¼Œç§»é™¤module.å‰ç¶´
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith('module.'):
                new_state_dict[k[7:]] = v  # ç§»é™¤ 'module.' å‰ç¶´
            else:
                new_state_dict[k] = v
                
        net_g.load_state_dict(new_state_dict)
        print("æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    else:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}")
    
    net_g = net_g.to(device)
    net_g.eval()
    return net_g

def test_model():
    """æ¸¬è©¦æ¨¡å‹ä¸¦è¨ˆç®—æŒ‡æ¨™"""
    # è¼‰å…¥æ¨¡å‹
    net_g = load_model(opt.model_path, device)
    
    # æº–å‚™è³‡æ–™é›†
    test_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
    ])
    
    test_set = LSUITestDataset(opt.dataset_path, transform=test_transform)
    test_loader = DataLoader(dataset=test_set, num_workers=0, batch_size=opt.batch_size, shuffle=False)
    
    print(f"æ¸¬è©¦è³‡æ–™æ•¸é‡: {len(test_set)}")
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    if opt.save_images:
        os.makedirs(opt.output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–æŒ‡æ¨™
    total_psnr = 0
    total_ssim = 0
    total_images = 0
    
    print("é–‹å§‹æ¸¬è©¦...")
    print("-" * 60)
    
    with torch.no_grad():
        for i, batch in enumerate(test_loader):
            rgb_input, target, img_names = batch[0].to(device), batch[1].to(device), batch[2]
            
            # æ¨¡å‹æ¨è«– - ä½¿ç”¨ RGB_input ä½œç‚ºåƒæ•¸åç¨±ä»¥åŒ¹é…æ¨¡å‹çš„ forward æ–¹æ³•
            try:
                prediction = net_g(rgb_input)
            except Exception as e:
                print(f"æ¨¡å‹æ¨è«–éŒ¯èª¤: {e}")
                print(f"è¼¸å…¥å½¢ç‹€: {rgb_input.shape}")
                continue
            
            # ç¢ºä¿è¼¸å‡ºå½¢ç‹€æ­£ç¢º
            if prediction.shape != target.shape:
                print(f"è­¦å‘Š: é æ¸¬è¼¸å‡ºå½¢ç‹€ {prediction.shape} èˆ‡ç›®æ¨™å½¢ç‹€ {target.shape} ä¸åŒ¹é…")
                # å¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨é€™è£¡èª¿æ•´è¼¸å‡ºå°ºå¯¸
                if prediction.shape[2:] != target.shape[2:]:
                    prediction = torch.nn.functional.interpolate(
                        prediction, size=target.shape[2:], mode='bilinear', align_corners=False
                    )
            
            # è¨ˆç®—æ¯å¼µåœ–ç‰‡çš„PSNRå’ŒSSIM
            for j in range(rgb_input.size(0)):
                pred_np = prediction[j].cpu().permute(1, 2, 0).numpy()
                target_np = target[j].cpu().permute(1, 2, 0).numpy()
                
                # ç¢ºä¿æ•¸å€¼ç¯„åœåœ¨[0, 1]
                pred_np = np.clip(pred_np, 0, 1)
                target_np = np.clip(target_np, 0, 1)
                
                # è¨ˆç®—PSNRå’ŒSSIM
                try:
                    img_psnr = psnr(target_np, pred_np, data_range=1.0)
                    img_ssim = ssim(target_np, pred_np, multichannel=True, data_range=1.0, win_size=3)
                    
                    total_psnr += img_psnr
                    total_ssim += img_ssim
                    total_images += 1
                    
                    print(f"åœ–ç‰‡ {img_names[j]}: PSNR = {img_psnr:.2f} dB, SSIM = {img_ssim:.4f}")
                except Exception as e:
                    print(f"è¨ˆç®—æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤ (åœ–ç‰‡ {img_names[j]}): {e}")
                    continue
                
                # å„²å­˜çµæœåœ–ç‰‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if opt.save_images:
                    # åˆä½µåŸåœ–ã€é æ¸¬åœ–å’Œç›®æ¨™åœ–
                    combined = torch.cat((rgb_input[j], prediction[j], target[j]), 2)  # åœ¨å¯¬åº¦æ–¹å‘æ‹¼æ¥
                    save_img(combined.cpu(), os.path.join(opt.output_dir, f"result_{img_names[j]}"))
            
            # æ¯10å€‹batché¡¯ç¤ºä¸€æ¬¡é€²åº¦
            if (i + 1) % 10 == 0 or (i + 1) == len(test_loader):
                current_avg_psnr = total_psnr / total_images
                current_avg_ssim = total_ssim / total_images
                print(f"é€²åº¦: {i+1}/{len(test_loader)} batches, "
                      f"ç›®å‰å¹³å‡ PSNR: {current_avg_psnr:.2f} dB, "
                      f"ç›®å‰å¹³å‡ SSIM: {current_avg_ssim:.4f}")
                print("-" * 60)
    
    # è¨ˆç®—æœ€çµ‚å¹³å‡å€¼
    if total_images > 0:
        avg_psnr = total_psnr / total_images
        avg_ssim = total_ssim / total_images
        
        print("\n" + "=" * 60)
        print("æ¸¬è©¦å®Œæˆï¼æœ€çµ‚çµæœ:")
        print("=" * 60)
        print(f"ç¸½æ¸¬è©¦åœ–ç‰‡æ•¸é‡: {total_images}")
        print(f"å¹³å‡ PSNR: {avg_psnr:.2f} dB")
        print(f"å¹³å‡ SSIM: {avg_ssim:.4f}")
        print("=" * 60)
        
        # å„²å­˜çµæœåˆ°æ–‡ä»¶ - ä½¿ç”¨è¿½åŠ æ¨¡å¼ä»¥ä¿ç•™æ­·å²è¨˜éŒ„
        result_file = os.path.join(opt.output_dir if opt.save_images else '.', 'test_results.txt')
        
        # æ·»åŠ æ™‚é–“æˆ³è¨˜ä»¥å€åˆ†ä¸åŒæ¬¡çš„æ¸¬è©¦
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        with open(result_file, 'a', encoding='utf-8') as f:  # ä½¿ç”¨ 'a' æ¨¡å¼è¿½åŠ è€Œä¸æ˜¯è¦†å¯«
            f.write(f"\n{'='*60}\n")
            f.write(f"æ¸¬è©¦æ™‚é–“: {timestamp}\n")
            f.write(f"æ¨¡å‹æª”æ¡ˆ: {opt.model_path}\n")
            f.write(f"æ¸¬è©¦è³‡æ–™é›†: {opt.dataset_path}\n")
            f.write(f"ç¸½æ¸¬è©¦åœ–ç‰‡æ•¸é‡: {total_images}\n")
            f.write(f"å¹³å‡ PSNR: {avg_psnr:.2f} dB\n")
            f.write(f"å¹³å‡ SSIM: {avg_ssim:.4f}\n")
            f.write(f"{'='*60}\n")
        
        print(f"è©³ç´°çµæœå·²å„²å­˜è‡³: {result_file}")
        
        return avg_psnr, avg_ssim
    else:
        print("æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦åœ–ç‰‡ï¼")
        return None, None

if __name__ == '__main__':
    print("=" * 70)
    print("Spectroformer (mymodel) æ¨¡å‹æ¸¬è©¦è…³æœ¬")
    print("=" * 70)
    print(f"æ¨¡å‹æª”æ¡ˆ: {opt.model_path}")
    print(f"æ¸¬è©¦è³‡æ–™é›†: {opt.dataset_path}")
    print(f"æ‰¹æ¬¡å¤§å°: {opt.batch_size}")
    print(f"æ˜¯å¦å„²å­˜åœ–ç‰‡: {opt.save_images}")
    print(f"è¼¸å‡ºç›®éŒ„: {opt.output_dir}")
    print("=" * 70)
    print()
    
    # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(opt.model_path):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ {opt.model_path}")
        print("è«‹ç¢ºèªæ¨¡å‹æª”æ¡ˆè·¯å¾‘æ˜¯å¦æ­£ç¢º")
        exit(1)
    
    # æª¢æŸ¥è³‡æ–™é›†è·¯å¾‘æ˜¯å¦å­˜åœ¨
    if not os.path.exists(opt.dataset_path):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°è³‡æ–™é›†è·¯å¾‘ {opt.dataset_path}")
        print("è«‹ç¢ºèªè³‡æ–™é›†è·¯å¾‘æ˜¯å¦æ­£ç¢º")
        exit(1)
    
    try:
        avg_psnr, avg_ssim = test_model()
        if avg_psnr is not None:
            print(f"\nâœ… æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“Š æœ€çµ‚çµæœ: PSNR = {avg_psnr:.2f} dB, SSIM = {avg_ssim:.4f}")
            print("\nä½¿ç”¨ç¯„ä¾‹å‘½ä»¤:")
            print(f"python test_model.py --model_path {opt.model_path} --dataset_path {opt.dataset_path}")
        else:
            print("âŒ æ¸¬è©¦å¤±æ•—: æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•åœ–ç‰‡")
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        print("\nè«‹æª¢æŸ¥ä»¥ä¸‹é …ç›®:")
        print("1. æ¨¡å‹æª”æ¡ˆæ˜¯å¦æ­£ç¢º")
        print("2. è³‡æ–™é›†è·¯å¾‘æ˜¯å¦æ­£ç¢º")
        print("3. GPU è¨˜æ†¶é«”æ˜¯å¦è¶³å¤ ")
        print("4. ç›¸ä¾å¥—ä»¶æ˜¯å¦å·²å®‰è£")
        print("\nè©³ç´°éŒ¯èª¤ä¿¡æ¯:")
        import traceback
        traceback.print_exc()
