"""
Spectroformer è¨“ç·´è…³æœ¬ - é‡æ§‹ç‰ˆ
æ”¯æ´å¤š GPU è¨“ç·´ã€æª¢æŸ¥é»æ¢å¾©ã€è‡ªå‹•ä¿å­˜æœ€ä½³æ¨¡å‹
"""
from __future__ import print_function
import argparse
import os
from datetime import datetime
from torchvision import transforms
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision.models import vgg19
from PIL import Image
from tqdm import tqdm
import torch.nn.functional as F
from pytorch_msssim import MS_SSIM
from spectroformer_paper import mymodel
import torch.backends.cudnn as cudnn
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

# ==================== æ•¸æ“šé›†é¡åˆ¥ ====================

class LSUITrainingDataset(Dataset):
    """LSUI è¨“ç·´è³‡æ–™é›†"""
    def __init__(self, data_path, transform=None):
        self.data_path = os.path.join(data_path, 'train')
        self.degraded_path = os.path.join(self.data_path, 'input')
        self.gt_path = os.path.join(self.data_path, 'gt')
        self.image_files = os.listdir(self.degraded_path)
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        degraded_img = Image.open(os.path.join(self.degraded_path, img_name)).convert('RGB')
        gt_img = Image.open(os.path.join(self.gt_path, img_name)).convert('RGB')
        
        if self.transform:
            degraded_img = self.transform(degraded_img)
            gt_img = self.transform(gt_img)
            
        return degraded_img, gt_img, img_name

class LSUITestDataset(Dataset):
    """LSUI æ¸¬è©¦è³‡æ–™é›†"""
    def __init__(self, data_path, transform=None):
        self.data_path = os.path.join(data_path, 'test')
        self.degraded_path = os.path.join(self.data_path, 'input')
        self.gt_path = os.path.join(self.data_path, 'gt')
        self.image_files = os.listdir(self.degraded_path)
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        degraded_img = Image.open(os.path.join(self.degraded_path, img_name)).convert('RGB')
        gt_img = Image.open(os.path.join(self.gt_path, img_name)).convert('RGB')

        if self.transform:
            degraded_img = self.transform(degraded_img)
            gt_img = self.transform(gt_img)
            
        return degraded_img, gt_img, img_name

# ==================== æå¤±å‡½æ•¸ ====================

class CharbonnierLoss(nn.Module):
    def __init__(self, eps=1e-3):
        super(CharbonnierLoss, self).__init__()
        self.eps = eps
    def forward(self, x, y):
        diff = x - y
        loss = torch.mean(torch.sqrt((diff * diff) + (self.eps*self.eps)))
        return loss

class WeightedLoss(nn.Module):
    """Weighted Loss for multiple loss components"""
    def __init__(self, num_weights):
        super(WeightedLoss, self).__init__()
        self.num_weights = num_weights
        self.weights = nn.Parameter(torch.rand(1, num_weights))
        self.softmax_l = nn.Softmax(dim=1)

    def forward(self, *argv):
        loss = 0
        weights = self.softmax_l(self.weights)
        for idx, arg in enumerate(argv):
            loss += arg * weights[0, idx]
        return loss

class GradientLoss(nn.Module):
    def __init__(self):
        super(GradientLoss, self).__init__()
        kernel_g = [[[0,1,0],[1,-4,1],[0,1,0]],
                    [[0,1,0],[1,-4,1],[0,1,0]],
                    [[0,1,0],[1,-4,1],[0,1,0]]]
        kernel_g = torch.FloatTensor(kernel_g).unsqueeze(0).permute(1, 0, 2, 3)
        self.weight_g = nn.Parameter(data=kernel_g, requires_grad=False)

    def forward(self, x, xx):
        y = x
        yy = xx
        gradient_x = F.conv2d(y, self.weight_g.to(y.device), groups=3)
        gradient_xx = F.conv2d(yy, self.weight_g.to(yy.device), groups=3)
        l = nn.L1Loss()
        return l(gradient_x, gradient_xx)

class VGGPerceptualLoss(nn.Module):
    def __init__(self, device):
        super(VGGPerceptualLoss, self).__init__()
        vgg = vgg19(weights='DEFAULT').features[:35].eval().to(device)
        self.vgg = nn.Sequential(*vgg)
        for param in self.vgg.parameters():
            param.requires_grad = False
    def forward(self, x, y):
        return F.l1_loss(self.vgg(x), self.vgg(y))

# ==================== å·¥å…·å‡½æ•¸ ====================

def init_weights(m):
    """æ¬Šé‡åˆå§‹åŒ–"""
    if isinstance(m, nn.Conv2d):
        nn.init.xavier_uniform_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Linear):
        nn.init.xavier_uniform_(m.weight)
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.LayerNorm):
        nn.init.constant_(m.bias, 0)
        nn.init.constant_(m.weight, 1.0)

def get_scheduler(optimizer, opt):
    """ç²å–å­¸ç¿’ç‡èª¿åº¦å™¨"""
    if opt.lr_policy == 'lambda':
        def lambda_rule(epoch):
            lr_l = 1.0 - max(0, epoch + opt.epoch_count - opt.niter) / float(opt.niter_decay + 1)
            return lr_l
        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)
    elif opt.lr_policy == 'step':
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)
    elif opt.lr_policy == 'plateau':
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)
    else:
        return NotImplementedError('learning rate policy [%s] is not implemented' % opt.lr_policy)
    return scheduler

def update_learning_rate(scheduler, optimizer):
    """æ›´æ–°å­¸ç¿’ç‡"""
    scheduler.step()

def save_img(img_tensor, filename):
    """å°‡å¼µé‡ä¿å­˜ç‚ºåœ–ç‰‡"""
    if len(img_tensor.shape) == 3:
        img = transforms.ToPILImage()(img_tensor.clamp(0, 1))
        img.save(filename)

# ==================== ä¸»è¨“ç·´å‡½æ•¸ ====================

def main():
    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser(description='Spectroformer è¨“ç·´è…³æœ¬')
    # --- è³‡æ–™é›†èˆ‡æ‰¹æ¬¡å¤§å° ---
    parser.add_argument('--dataset_path', default='/danny/Spectroformer_model/LSUI', help='LSUI è³‡æ–™é›†çš„è·¯å¾‘')
    parser.add_argument('--batch_size', type=int, default=6, help='è¨“ç·´æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--test_batch_size', type=int, default=6, help='æ¸¬è©¦æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--threads', type=int, default=0, help='è³‡æ–™è¼‰å…¥å™¨ä½¿ç”¨çš„åŸ·è¡Œç·’æ•¸é‡')

    # --- è¨“ç·´é€±æœŸèˆ‡å­¸ç¿’ç‡ ---
    parser.add_argument('--niter', type=int, default=50, help='å›ºå®šå­¸ç¿’ç‡çš„è¨“ç·´é€±æœŸæ•¸')
    parser.add_argument('--niter_decay', type=int, default=500, help='å­¸ç¿’ç‡è¡°æ¸›çš„è¨“ç·´é€±æœŸæ•¸')
    parser.add_argument('--lr', type=float, default=0.001, help='åˆå§‹å­¸ç¿’ç‡')
    parser.add_argument('--lr_policy', type=str, default='lambda', help='å­¸ç¿’ç‡ç­–ç•¥')
    parser.add_argument('--epoch_count', type=int, default=0, help='èµ·å§‹çš„ epoch è¨ˆæ•¸')

    # --- å„ªåŒ–å™¨èˆ‡æ¨¡å‹å„²å­˜ ---
    parser.add_argument('--beta1', type=float, default=0.5, help='Adam å„ªåŒ–å™¨çš„ beta1 åƒæ•¸')
    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints', help='å„²å­˜æ¨¡å‹æ¬Šé‡çš„è³‡æ–™å¤¾')
    parser.add_argument('--output_dir', type=str, default='./images', help='å„²å­˜è¨“ç·´/æ¸¬è©¦å½±åƒçš„è³‡æ–™å¤¾')
    parser.add_argument('--resume', type=str, default='', help='æ¢å¾©è¨“ç·´çš„æª¢æŸ¥é»è·¯å¾‘')

    # --- ç’°å¢ƒè¨­å®š ---
    parser.add_argument('--cuda', action='store_true', default=True, help='æ˜¯å¦ä½¿ç”¨ CUDA')
    parser.add_argument('--seed', type=int, default=123, help='éš¨æ©Ÿç¨®å­')
    
    opt = parser.parse_args()
    
    # ç”Ÿæˆè¨“ç·´é‹è¡Œçš„å”¯ä¸€æ¨™è­˜ç¬¦ï¼ˆæ™‚é–“æˆ³ï¼‰
    RUN_TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    print(opt)

    os.environ["CUDA_VISIBLE_DEVICES"] = "1"
    if opt.cuda and not torch.cuda.is_available():
        raise Exception("æœªæ‰¾åˆ° GPUï¼Œè«‹åœ¨æ²’æœ‰ --cuda çš„æƒ…æ³ä¸‹åŸ·è¡Œ")

    cudnn.benchmark = True
    torch.manual_seed(opt.seed)
    if opt.cuda:
        torch.cuda.manual_seed(opt.seed)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è£ç½®: {device}")

    # åˆå§‹åŒ–æ¨¡å‹
    net_g = mymodel()
    net_g = net_g.to(device)

    # å¤šå¡è¨“ç·´è¨­ç½®
    if torch.cuda.device_count() > 1:
        print(f"æª¢æ¸¬åˆ° {torch.cuda.device_count()} å¼µ GPU")
        net_g = torch.nn.DataParallel(net_g)
        print(f"ä½¿ç”¨ {torch.cuda.device_count()} å¼µ GPU é€²è¡Œè¨“ç·´")
    else:
        print("åªæª¢æ¸¬åˆ° 1 å¼µ GPUï¼Œä½¿ç”¨å–®å¡è¨“ç·´")

    net_g = net_g.to(device)

    # æ¬Šé‡åˆå§‹åŒ–
    net_g.apply(init_weights)
    print('æ¨¡å‹åƒæ•¸ç¸½é‡:', sum(p.numel() for p in net_g.parameters() if p.requires_grad))

    # æ¢å¾©è¨“ç·´æª¢æŸ¥é»
    start_epoch = opt.epoch_count
    if opt.resume:
        if os.path.isfile(opt.resume):
            print(f"è¼‰å…¥æª¢æŸ¥é» '{opt.resume}'")
            checkpoint = torch.load(opt.resume)
            if isinstance(net_g, torch.nn.DataParallel):
                net_g.module.load_state_dict(checkpoint)
            else:
                net_g.load_state_dict(checkpoint)
            # å¾æª”åä¸­æå–epoch
            epoch_num = int(opt.resume.split('_')[-1].split('.')[0])
            start_epoch = epoch_num
            print(f"å¾ç¬¬ {start_epoch} å€‹epochæ¢å¾©è¨“ç·´")
        else:
            print(f"æ‰¾ä¸åˆ°æª¢æŸ¥é»æ–‡ä»¶: {opt.resume}")

    # è¼‰å…¥è³‡æ–™é›†
    print('===> è¼‰å…¥è³‡æ–™é›†')
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
    ])
    test_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
    ])

    train_set = LSUITrainingDataset(opt.dataset_path, transform=train_transform)
    test_set = LSUITestDataset(opt.dataset_path, transform=test_transform)
    training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batch_size, shuffle=True, pin_memory=True)
    testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.test_batch_size, shuffle=False, pin_memory=True)

    print(f"è¨“ç·´è³‡æ–™æ•¸é‡: {len(train_set)}")
    print(f"æ¸¬è©¦è³‡æ–™æ•¸é‡: {len(test_set)}")

    # åˆå§‹åŒ–æå¤±å‡½æ•¸
    Charbonnier_loss = CharbonnierLoss().to(device)
    Gradient_Loss = GradientLoss().to(device)
    L_per = VGGPerceptualLoss(device).to(device)
    MS_SSIM_loss = MS_SSIM(win_size=11, win_sigma=1.5, data_range=1, size_average=True, channel=3).to(device)
    Weighted_Loss4 = WeightedLoss(4).to(device)

    # åˆå§‹åŒ–å„ªåŒ–å™¨å’Œèª¿åº¦å™¨
    optimizer_g = optim.Adam(net_g.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
    net_g_scheduler = get_scheduler(optimizer_g, opt)

    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    train_output_dir = os.path.join(opt.output_dir, f'train_{RUN_TIMESTAMP}')
    test_output_dir = os.path.join('./test', f'test_{RUN_TIMESTAMP}')
    checkpoint_dir = os.path.join('checkpoint', opt.dataset_path.split('/')[-1], f'run_{RUN_TIMESTAMP}')

    os.makedirs(train_output_dir, exist_ok=True)
    os.makedirs(test_output_dir, exist_ok=True)
    os.makedirs(checkpoint_dir, exist_ok=True)

    print(f"\n=== è¨“ç·´é‹è¡Œ: {RUN_TIMESTAMP} ===")
    print(f"è¨“ç·´åœ–ç‰‡è¼¸å‡ºç›®éŒ„: {train_output_dir}")
    print(f"æ¸¬è©¦åœ–ç‰‡è¼¸å‡ºç›®éŒ„: {test_output_dir}")
    print(f"æ¨¡å‹æª¢æŸ¥é»ç›®éŒ„: {checkpoint_dir}")
    print("=" * 50)

    # è¿½è¹¤æœ€ä½³æ¨¡å‹
    best_psnr = 0.0
    best_epoch = 0

    # è¨“ç·´å¾ªç’°
    for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):
        # è¨“ç·´
        epoch_loss = 0.0
        num_batches = 0
        
        # å‰µå»ºé€²åº¦æ¢
        progress_bar = tqdm(training_data_loader, desc=f'Epoch {epoch}/{opt.niter + opt.niter_decay}', 
                           unit='batch', leave=True)
        
        for iteration, batch in enumerate(progress_bar, 1):
            # å‰å‘å‚³æ’­
            rgb, tar, indx = batch[0].to(device), batch[1].to(device), batch[2]
            
            # Spectroformer (mymodel) è¿”å›å–®ä¸€è¼¸å‡º
            fake_b = net_g(rgb)

            ######################
            # æ›´æ–°ç”Ÿæˆå™¨
            ######################
            optimizer_g.zero_grad()
          
            # è¨ˆç®—æå¤±ï¼ˆä½¿ç”¨4å€‹æå¤±çµ„ä»¶çš„åŠ æ¬Šçµ„åˆï¼‰
            loss_char = Charbonnier_loss(tar, fake_b)
            loss_per = L_per(fake_b, tar)
            loss_grad = Gradient_Loss(fake_b, tar)
            loss_ssim = 1 - MS_SSIM_loss(fake_b, tar)
            loss_g = Weighted_Loss4(loss_char, loss_per, loss_grad, loss_ssim)
            
            # æª¢æŸ¥æå¤±æ˜¯å¦ç‚ºnanæˆ–inf
            if torch.isnan(loss_g) or torch.isinf(loss_g):
                print(f"è­¦å‘Šï¼šåœ¨epoch {epoch}, iteration {iteration} æª¢æ¸¬åˆ°ç•°å¸¸æå¤±: {loss_g.item()}")
                print(f"  - Charbonnieræå¤±: {loss_char.item():.6f}")
                print(f"  - æ„ŸçŸ¥æå¤±: {loss_per.item():.6f}")
                print(f"  - æ¢¯åº¦æå¤±: {loss_grad.item():.6f}")
                print(f"  - MS-SSIMæå¤±: {loss_ssim.item():.6f}")
                
                # è·³éé€™å€‹batchçš„æ›´æ–°
                optimizer_g.zero_grad()
                continue
                
            loss_g.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(net_g.parameters(), max_norm=1.0)
            
            optimizer_g.step()
            
            # ç´¯è¨ˆæå¤±å’Œæ‰¹æ¬¡æ•¸
            epoch_loss += loss_g.item()
            num_batches += 1
            
            # æ›´æ–°é€²åº¦æ¢
            current_loss = epoch_loss / num_batches
            progress_bar.set_postfix({
                'Loss': f'{loss_g.item():.4f}',
                'Avg_Loss': f'{current_loss:.4f}',
                'LR': f'{optimizer_g.param_groups[0]["lr"]:.6f}'
            })

            if iteration % 20 == 0:
                # è¼¸å‡ºå¯è¦–åŒ–
                out_image = torch.cat((rgb, fake_b, tar), 3)
                out_image = out_image[0].detach().squeeze(0).cpu()
                save_img(out_image, os.path.join(train_output_dir, indx[0]))
        
        # é—œé–‰é€²åº¦æ¢ä¸¦é¡¯ç¤ºepochçµ±è¨ˆ
        progress_bar.close()
        if num_batches > 0:
            avg_epoch_loss = epoch_loss / num_batches
            print(f"\nEpoch {epoch} å®Œæˆ - å¹³å‡æå¤±: {avg_epoch_loss:.4f}")
            print(f"å­¸ç¿’ç‡: {optimizer_g.param_groups[0]['lr']:.6f}")
            print("-" * 50)

        update_learning_rate(net_g_scheduler, optimizer_g)
      
        # æ¸¬è©¦
        # åˆå§‹åŒ–ç¸½é«”æŒ‡æ¨™
        total_psnr = 0
        total_ssim = 0
        total_images = 0

        # å‰µå»ºæ¸¬è©¦é€²åº¦æ¢
        test_progress = tqdm(testing_data_loader, desc=f'Testing Epoch {epoch}', 
                            unit='batch', leave=False)
        
        for test_iter, batch in enumerate(test_progress, 1):
            rgb_input, target, ind = batch[0].to(device), batch[1].to(device), batch[2]
            with torch.no_grad():
                # Spectroformer (mymodel) è¿”å›å–®ä¸€è¼¸å‡º
                prediction = net_g(rgb_input)
            
            out = torch.cat((prediction, target), 3)
            output_cat = out[0].detach().squeeze(0).cpu()
            save_img(output_cat, os.path.join(test_output_dir, ind[0]))

            # è¨ˆç®—æ•´å€‹ batch çš„ PSNR å’Œ SSIM
            batch_psnr = 0
            batch_ssim = 0
            for i in range(rgb_input.size(0)):
                prediction_np = prediction[i].cpu().permute(1, 2, 0).numpy()
                target_np = target[i].cpu().permute(1, 2, 0).numpy()

                # ç´¯åŠ æ¯å¼µåœ–ç‰‡çš„ PSNR å’Œ SSIM
                img_psnr = psnr(target_np, prediction_np, data_range=1.0)
                img_ssim = ssim(target_np, prediction_np, multichannel=True, data_range=1.0, win_size=3)
                
                batch_psnr += img_psnr
                batch_ssim += img_ssim
                
                # ç´¯åŠ åˆ°ç¸½é«”æŒ‡æ¨™
                total_psnr += img_psnr
                total_ssim += img_ssim
                total_images += 1

            # è¨ˆç®— batch å¹³å‡å€¼
            batch_psnr /= rgb_input.size(0)
            batch_ssim /= rgb_input.size(0)
            
            # æ›´æ–°æ¸¬è©¦é€²åº¦æ¢
            test_progress.set_postfix({
                'PSNR': f'{batch_psnr:.2f}',
                'SSIM': f'{batch_ssim:.4f}'
            })

        # è¨ˆç®—ä¸¦é¡¯ç¤ºå…¨éƒ¨æ¸¬è©¦å½±åƒçš„å¹³å‡å€¼
        if total_images > 0:
            avg_psnr = total_psnr / total_images
            avg_ssim = total_ssim / total_images
            # é—œé–‰æ¸¬è©¦é€²åº¦æ¢
            test_progress.close()
            
            print(f"\n=== Epoch {epoch} æ¸¬è©¦çµæœ ===")
            print(f"å…¨éƒ¨æ¸¬è©¦å½±åƒå¹³å‡ PSNR: {avg_psnr:.2f} dB")
            print(f"å…¨éƒ¨æ¸¬è©¦å½±åƒå¹³å‡ SSIM: {avg_ssim:.4f}")
            print(f"ç¸½æ¸¬è©¦å½±åƒæ•¸é‡: {total_images}")
            print("=" * 50)

        # åªä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆæ ¹æ“š PSNRï¼‰
        if total_images > 0 and avg_psnr > best_psnr:
            best_psnr = avg_psnr
            best_epoch = epoch
            
            # åˆªé™¤ä¹‹å‰çš„æœ€ä½³æ¨¡å‹
            best_model_path = os.path.join(checkpoint_dir, "best_model.pth")
            
            # å¦‚æœä½¿ç”¨ DataParallelï¼Œä¿å­˜æ™‚éœ€è¦ä½¿ç”¨ .module
            if isinstance(net_g, torch.nn.DataParallel):
                torch.save(net_g.module.state_dict(), best_model_path)
            else:
                torch.save(net_g.state_dict(), best_model_path)
            
            print(f"ğŸ† æ–°çš„æœ€ä½³æ¨¡å‹ï¼PSNR: {best_psnr:.2f} dB (Epoch {best_epoch})")
            print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {best_model_path}")
        else:
            print(f"ç•¶å‰æœ€ä½³: Epoch {best_epoch} with PSNR: {best_psnr:.2f} dB")

    print(f"\nè¨“ç·´å®Œæˆï¼æœ€ä½³æ¨¡å‹: Epoch {best_epoch} with PSNR: {best_psnr:.2f} dB")


if __name__ == '__main__':
    main()
